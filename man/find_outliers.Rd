% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/joeyr_filter.R
\name{find_outliers}
\alias{find_outliers}
\title{Detect outliers}
\usage{
find_outliers(..., keep = 0.95)
}
\arguments{
\item{...}{A list of columns in your data that should be included when
calculating the Mahalanobis distance. The column names should not be in
quotes. For vowel data, you typically include F1 and F2. You may also 
want to include F3, duration, and any other continuous variable.}

\item{keep}{A number indicating the proportion of data (per group) to keep.
By default, it's 0.95 so it keeps 95\% of the data and filters out 5\%.}
}
\value{
A vector of TRUE/FALSE values. They are in the same order as the original
  dataset. Observations that are considered outliers have the value TRUE. It is 
  easiest to work with this by appending this vector to your dataframe.
}
\description{
This is an implementation of the Mahalanobis Distance that is less sensitive
to outliers. Instead of a blanket filter applying all at once, it iteratively 
removes points one at a time until a predetermined proportion of data has been
removed.
}
\details{
The Mahalanobis distance function is somewhat sensitive to outliers, so if
there are extreme values in your data, the mean value will be off-center from
the centroid of your observations. Consequently, the Mahalanobis Distances
will be based on this off-center points, which is probably not desirable. 
This function alleviates this sensitivity to outliers by implementing a 
one-at-a-time method.

When you run this function, it will first calculate Mahalanobis distance from
the mean of all values. It detects the point furthest from the mean and
removes it. Then, it recalculates the Mahalanobis distance with the remaining
values and again removes the furthest value. It continues this
recalculation-and-removal method until a predetermined proportion of values
has been removed.
}
\note{
While not required, you should typically "group" your data before applying
  this function. For example, you can group your data by speaker and vowel so 
  that the function applies independently for each vowel for each speaker. I 
  normally do this with \code{dplyr::group_by(speaker, word)}
  
  Note also that in American English, allophonic variation of some vowels is so 
  great that grouping by vowel may not be enough. If you're working with /u/ for
  example, it's a good idea to split it into three groups: post-coronal, pre-lateral,
  and elsewhere. For /Ã¦/, it's a good idea to group prenasal tokens separatly. 
  If you're using FAVE/DARLA/MFA output, the NORTH and FORCE classes of words
  are transcribed with AO, so it's a good idea to treat those separately. The point 
  is to be mindful of allophonic variation in your data and that it's a good 
  idea to group the data by vowel \emph{class} rather than by vowel. You may have to 
  do some processing before the filter happens to get this to happen.
}
\examples{
# Load some data and group it by vowel.
require(dplyr)
joey_vowels <- read.csv("http://joeystanley.com/data/joey.csv") \%>\%
   group_by(vowel)

# You can output the data to a column called something like 
# "is_outlier" and then filter values that are false.
joey_vowels \%>\%
   mutate(is_outlier = find_outliers(F1, F2, dur, keep = 0.95)) \%>\%
   filter(!is_outlier)

# Alternatively, you can skip a step and just keep the 
# data that are not outliers.
joey_vowels \%>\%
   filter(!find_outliers(F1, F2, dur, keep = 0.95))
}
